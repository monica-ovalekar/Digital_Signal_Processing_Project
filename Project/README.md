So, the idea is basically AUTO TUNE.
So, the musical scales are divided into 12 pitches each separated by a semitone – the difference in note
between two adjacent keys on a piano or frets on a guitar neck. The goal of pitch correction is to retune
a slightly high or low note to the nearest semitone.
In the system usually used by MIDI instruments in which pitch is assigned a number, with the 440-Hz A
being 69 and each semitone increasing or decreasing the pitch number by 1, it is related to frequency f
by a simple formula.
If an attempt at singing that a note came out at, say, 445 Hz instead, then we can code to correct the
frequency back down would ensure that the recording sounds in tune. It's easier with digital signals, but
for analog signals, we can sample and perform the same function. Although it is possible to alter analog
signals – those based directly on the electrical signal generated by a microphone, or by a guitar pickup –
a wider range of effects is possible when working with digital signals.
A digital signal uses discrete values rather than continuous ones, so converting an analog signal requires
taking sets of discrete points or samples (Higher sampling rates maybe? To mimic the original sound?).
These digital signals can be altered so that a sound produces the correct musical note by using a phase
vocoder. This works by first changing the duration of the sound without altering its frequency, and then
changing the frequency to both hit the correct pitch and restore the original duration.
It breaks an audio signal down into many small, overlapping frames and then changes the spacing of
those frames to change the total duration of the sound. In practice, this is a complicated task that
requires the use of the advanced math of Fourier transforms to convert the signal into a form that can
be manipulated in this way.
The sound is then resampled to take it back to its original duration and hit the desired note.
So, if the aim was to double the frequency then this would be as easy as picking one out of every two
samples and constructing a waveform from those. But to fit the signal back into its original length when
not scaling by an integer, interpolation is used to determine which bits of the sample should go at which
points.
We plan to make a GUI/App for the same.